{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f9c70bc",
   "metadata": {},
   "source": [
    "### IMPORT LIBRARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ccfa4d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from office365.runtime.auth.authentication_context import AuthenticationContext\n",
    "from office365.sharepoint.client_context import ClientContext\n",
    "from office365.sharepoint.files.file import File\n",
    "from office365.runtime.auth.client_credential import ClientCredential\n",
    "from office365.runtime.client_request_exception import ClientRequestException\n",
    "import datetime\n",
    "import pytz\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import glob\n",
    "import pyodbc\n",
    "import os \n",
    "import json\n",
    "from io import BytesIO\n",
    "import io\n",
    "import platform\n",
    "from function.PyToSp import *\n",
    "from tqdm import tqdm\n",
    "from urllib.parse import quote_plus\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, event\n",
    "import pyodbc\n",
    "import requests\n",
    "import inspect\n",
    "from validate import *\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "from urllib.parse import quote_plus\n",
    "import msal\n",
    "from itertools import chain\n",
    "from send_email import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8bee114",
   "metadata": {},
   "source": [
    "### CONNECT TO AZURE SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a39960d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "f = open ('database_information.json', \"r\")\n",
    "qq = json.loads(f.read())\n",
    "f.close()\n",
    "ini_cnt_str ='Driver={driver_str};Server=tcp:hkazdevsqld3vnreserch.database.windows.net,1433;database={database};Uid={username};Pwd={password};Encrypt=yes;Authentication=ActiveDirectoryPassword;Connection Timeout=30;'.format(**qq)\n",
    "quoted = quote_plus(ini_cnt_str)\n",
    "cnt_str = 'mssql+pyodbc:///?odbc_connect={}'.format(quoted)\n",
    "engine = create_engine(cnt_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81420039",
   "metadata": {},
   "source": [
    "### CONNECT TO SHAREPOINT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b0587ba",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Web site title: S22M Research & BI Hub _ Successful Connection!\n"
     ]
    }
   ],
   "source": [
    "header_BIHub = 'share_point_BIHub'\n",
    "config_BIHub = read_config_json(config_path, header_BIHub)\n",
    "BIHub = SharePoint(config_BIHub)\n",
    "BIHub.check_connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3cf9cd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder name: /sites/BIHub/Shared Documents/Advisory Data/Dim_Dictionary/Developer\n"
     ]
    }
   ],
   "source": [
    "#Tất cả các tỉnh\n",
    "relative_url = \"/sites/BIHub/Shared Documents/Advisory Data/Dim_Dictionary\"\n",
    "sp_object = relative_url.split('/')[2].replace('-','')\n",
    "list_folder = eval(sp_object).get_content_url(relative_url,return_list_folder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4319872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder name: \n",
      "Files name: /sites/BIHub/Shared Documents/Advisory Data/Dim_Dictionary/Developer/FF_Developer_Dictionary.csv\n",
      "Files name: /sites/BIHub/Shared Documents/Advisory Data/Dim_Dictionary/Developer/Developer_Dictionary.xlsx\n"
     ]
    }
   ],
   "source": [
    "#-------------------------------------------------------\n",
    "df_summ_file = pd.DataFrame({'Name':[],'ServerRelativeUrl':[], 'TimeLastModified':[], 'ModTime':[], 'Modified_by_ID':[]})\n",
    "for i in list_folder:\n",
    "    df_summ_file = pd.concat([df_summ_file, eval(sp_object).get_content_url(i)])\n",
    "list_file = df_summ_file['ServerRelativeUrl'].to_list()\n",
    "#History file\n",
    "df_query=pd.DataFrame(df_summ_file).reset_index(drop=True)\n",
    "df_summ_file = df_summ_file.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5bc3144",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/sites/BIHub/Shared Documents/Advisory Data/Dim_Dictionary/Developer/Developer_Dictionary.xlsx']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = []\n",
    "for i in list_file:\n",
    "    Folder = i.split('/')[7]\n",
    "    if Folder == 'Developer_Dictionary.xlsx':\n",
    "        url.append(i)\n",
    "url        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9a49849",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(relative_url, file_url):\n",
    "    header_BIHub = 'share_point_BIHub'\n",
    "    config_BIHub = read_config_json(config_path, header_BIHub)\n",
    "    BIHub = SharePoint(config_BIHub)\n",
    "\n",
    "    sp_object = relative_url.split('/')[2].replace('-', '')\n",
    "    data_MS = BIHub.get_file_with_sheet_name(file_url, sheet_name='MainSector_Developer')\n",
    "    data_IP = BIHub.get_file_with_sheet_name(file_url, sheet_name='IP_Developer')\n",
    "    data = pd.concat([data_MS, data_IP], ignore_index=True)\n",
    "    # Convert data to DataFrame if it's not already\n",
    "    if not isinstance(data, pd.DataFrame):\n",
    "        data = pd.DataFrame(data)\n",
    "\n",
    "    # Remove irrelevant data\n",
    "    data.dropna(axis=0, how='all', inplace=True)  # remove blank rows\n",
    "    data.drop(data.columns[data.columns.str.contains('Unnamed')], axis=1, inplace=True)  # remove blank columns\n",
    "    data.columns = data.columns.str.strip().str.replace(r'\\s+', '', regex=True)  # strip column\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08aeac6",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "f0829aad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "#Create empty df for checking dictionary\n",
    "df_dict = pd.DataFrame(columns=['File_Name', 'Missing_Values', 'Flag'])\n",
    "df_temp_flat = pd.DataFrame()\n",
    "df_flat = pd.DataFrame()\n",
    "#-------------------------------------------------------\n",
    "'''Get data''' \n",
    "table_name = 'Developer_Dictionary'\n",
    "columns_that_need_unidecode = ['Cleaned_Developer']\n",
    "\n",
    "for file_url in tqdm(url):\n",
    "    data = get_data(relative_url, file_url)\n",
    "    data = remove_unformated_character(data)\n",
    "    data = pd.DataFrame(data)\n",
    "    for i in columns_that_need_unidecode:\n",
    "        data[i] = remove_unicode(data[i])\n",
    "    today = pd.to_datetime('today').strftime(\"%Y-%m-%d %H:%M:%S.%f\")[:-3]\n",
    "   \n",
    "    hold_data = data[data['Update_Developer'].isnull()]\n",
    "    new_row = data[data['Update_Developer'].notnull()]\n",
    "    new_row['Cleaned_Developer'] = new_row['Update_Developer']\n",
    "    new_row['Last_Update'] = today\n",
    "    new_row = new_row.drop('Update_Developer', axis=1)\n",
    "    hold_data = hold_data.drop('Update_Developer', axis=1)\n",
    "    data = pd.concat([hold_data, new_row], ignore_index=True)\n",
    "    # filtered_data = data[~data['Raw_Developer'].isin(pd.read_sql_query(\"SELECT Raw_Developer FROM GENERAL.Developer_Dictionary\", engine)['Raw_Developer'])]\n",
    "    # get_db= pd.read_sql_query(\"SELECT * FROM GENERAL.Developer_Dictionary\", engine)\n",
    "    # df_get_db = pd.DataFrame(get_db)\n",
    "    # filtered_data = data[~data['Raw_Developer'].isin(df_get_db['Raw_Developer'])]\n",
    "    data = data.dropna(subset=['Raw_Developer'])\n",
    "    data = data.drop('Update_Developer', axis=1)\n",
    "    data.to_sql(table_name, engine, index=False, if_exists='replace', schema='GENERAL')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\pnguyenhaiduong\\AppData\\Local\\Temp\\ipykernel_25088\\3842369159.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_row['Cleaned_Developer'] = new_row['Update_Developer']\n",
      "C:\\Users\\pnguyenhaiduong\\AppData\\Local\\Temp\\ipykernel_25088\\3842369159.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_row['Last_Update'] = today\n",
      "  0%|          | 0/1 [00:05<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ProgrammingError",
     "evalue": "(pyodbc.ProgrammingError) ('The SQL contains 0 parameter markers, but 1 parameters were supplied', 'HY000')\n[SQL: \n            UPDATE GENERAL.Developer_Dictionary\n            SET Cleaned_Developer = :cleaned_dev,\n                Last_Update = :last_update\n            WHERE Raw_Developer = :raw_dev AND Sector = :sector\n        ]\n[parameters: {'cleaned_dev': '379 Urban Development', 'last_update': '2023-12-06 16:43:44.934', 'raw_dev': '379 Urban Development Ltd.', 'sector': 'Main Sector'}]\n(Background on this error at: https://sqlalche.me/e/14/f405)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mProgrammingError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1819\u001b[0m, in \u001b[0;36mConnection._execute_context\u001b[1;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[0;32m   1818\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m evt_handled:\n\u001b[1;32m-> 1819\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdialect\u001b[39m.\u001b[39mdo_execute(\n\u001b[0;32m   1820\u001b[0m             cursor, statement, parameters, context\n\u001b[0;32m   1821\u001b[0m         )\n\u001b[0;32m   1823\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_events \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mengine\u001b[39m.\u001b[39m_has_events:\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\sqlalchemy\\engine\\default.py:732\u001b[0m, in \u001b[0;36mDefaultDialect.do_execute\u001b[1;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[0;32m    731\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdo_execute\u001b[39m(\u001b[39mself\u001b[39m, cursor, statement, parameters, context\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m--> 732\u001b[0m     cursor\u001b[39m.\u001b[39mexecute(statement, parameters)\n",
      "\u001b[1;31mProgrammingError\u001b[0m: ('The SQL contains 0 parameter markers, but 1 parameters were supplied', 'HY000')",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mProgrammingError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32mc:\\MainSystemProject\\research\\New_202306\\Import_Dictionary.ipynb Cell 14\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/MainSystemProject/research/New_202306/Import_Dictionary.ipynb#X15sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39m# Execute the query with the row values using parameterized query\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/MainSystemProject/research/New_202306/Import_Dictionary.ipynb#X15sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m \u001b[39mwith\u001b[39;00m engine\u001b[39m.\u001b[39mconnect() \u001b[39mas\u001b[39;00m conn:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/MainSystemProject/research/New_202306/Import_Dictionary.ipynb#X15sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m     conn\u001b[39m.\u001b[39mexecute(sql_query, cleaned_dev\u001b[39m=\u001b[39mrow[\u001b[39m'\u001b[39m\u001b[39mCleaned_Developer\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/MainSystemProject/research/New_202306/Import_Dictionary.ipynb#X15sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m                            last_update\u001b[39m=\u001b[39mtoday,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/MainSystemProject/research/New_202306/Import_Dictionary.ipynb#X15sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m                            raw_dev\u001b[39m=\u001b[39mrow[\u001b[39m'\u001b[39m\u001b[39mRaw_Developer\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/MainSystemProject/research/New_202306/Import_Dictionary.ipynb#X15sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m                            sector\u001b[39m=\u001b[39mrow[\u001b[39m'\u001b[39m\u001b[39mSector\u001b[39m\u001b[39m'\u001b[39m])\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1291\u001b[0m, in \u001b[0;36mConnection.execute\u001b[1;34m(self, statement, *multiparams, **params)\u001b[0m\n\u001b[0;32m   1282\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(statement, util\u001b[39m.\u001b[39mstring_types):\n\u001b[0;32m   1283\u001b[0m     util\u001b[39m.\u001b[39mwarn_deprecated_20(\n\u001b[0;32m   1284\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPassing a string to Connection.execute() is \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1285\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdeprecated and will be removed in version 2.0.  Use the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1288\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdriver-level SQL string.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1289\u001b[0m     )\n\u001b[1;32m-> 1291\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exec_driver_sql(\n\u001b[0;32m   1292\u001b[0m         statement,\n\u001b[0;32m   1293\u001b[0m         multiparams,\n\u001b[0;32m   1294\u001b[0m         params,\n\u001b[0;32m   1295\u001b[0m         _EMPTY_EXECUTION_OPTS,\n\u001b[0;32m   1296\u001b[0m         future\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m   1297\u001b[0m     )\n\u001b[0;32m   1299\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1300\u001b[0m     meth \u001b[39m=\u001b[39m statement\u001b[39m.\u001b[39m_execute_on_connection\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1595\u001b[0m, in \u001b[0;36mConnection._exec_driver_sql\u001b[1;34m(self, statement, multiparams, params, execution_options, future)\u001b[0m\n\u001b[0;32m   1585\u001b[0m         (\n\u001b[0;32m   1586\u001b[0m             statement,\n\u001b[0;32m   1587\u001b[0m             distilled_params,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1591\u001b[0m             statement, distilled_parameters, execution_options\n\u001b[0;32m   1592\u001b[0m         )\n\u001b[0;32m   1594\u001b[0m dialect \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdialect\n\u001b[1;32m-> 1595\u001b[0m ret \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_execute_context(\n\u001b[0;32m   1596\u001b[0m     dialect,\n\u001b[0;32m   1597\u001b[0m     dialect\u001b[39m.\u001b[39mexecution_ctx_cls\u001b[39m.\u001b[39m_init_statement,\n\u001b[0;32m   1598\u001b[0m     statement,\n\u001b[0;32m   1599\u001b[0m     distilled_parameters,\n\u001b[0;32m   1600\u001b[0m     execution_options,\n\u001b[0;32m   1601\u001b[0m     statement,\n\u001b[0;32m   1602\u001b[0m     distilled_parameters,\n\u001b[0;32m   1603\u001b[0m )\n\u001b[0;32m   1605\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m future:\n\u001b[0;32m   1606\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_events \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mengine\u001b[39m.\u001b[39m_has_events:\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1862\u001b[0m, in \u001b[0;36mConnection._execute_context\u001b[1;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[0;32m   1859\u001b[0m             branched\u001b[39m.\u001b[39mclose()\n\u001b[0;32m   1861\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m-> 1862\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_dbapi_exception(\n\u001b[0;32m   1863\u001b[0m         e, statement, parameters, cursor, context\n\u001b[0;32m   1864\u001b[0m     )\n\u001b[0;32m   1866\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:2043\u001b[0m, in \u001b[0;36mConnection._handle_dbapi_exception\u001b[1;34m(self, e, statement, parameters, cursor, context)\u001b[0m\n\u001b[0;32m   2041\u001b[0m     util\u001b[39m.\u001b[39mraise_(newraise, with_traceback\u001b[39m=\u001b[39mexc_info[\u001b[39m2\u001b[39m], from_\u001b[39m=\u001b[39me)\n\u001b[0;32m   2042\u001b[0m \u001b[39melif\u001b[39;00m should_wrap:\n\u001b[1;32m-> 2043\u001b[0m     util\u001b[39m.\u001b[39mraise_(\n\u001b[0;32m   2044\u001b[0m         sqlalchemy_exception, with_traceback\u001b[39m=\u001b[39mexc_info[\u001b[39m2\u001b[39m], from_\u001b[39m=\u001b[39me\n\u001b[0;32m   2045\u001b[0m     )\n\u001b[0;32m   2046\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   2047\u001b[0m     util\u001b[39m.\u001b[39mraise_(exc_info[\u001b[39m1\u001b[39m], with_traceback\u001b[39m=\u001b[39mexc_info[\u001b[39m2\u001b[39m])\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\sqlalchemy\\util\\compat.py:208\u001b[0m, in \u001b[0;36mraise_\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m    205\u001b[0m     exception\u001b[39m.\u001b[39m__cause__ \u001b[39m=\u001b[39m replace_context\n\u001b[0;32m    207\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 208\u001b[0m     \u001b[39mraise\u001b[39;00m exception\n\u001b[0;32m    209\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m     \u001b[39m# credit to\u001b[39;00m\n\u001b[0;32m    211\u001b[0m     \u001b[39m# https://cosmicpercolator.com/2016/01/13/exception-leaks-in-python-2-and-3/\u001b[39;00m\n\u001b[0;32m    212\u001b[0m     \u001b[39m# as the __traceback__ object creates a cycle\u001b[39;00m\n\u001b[0;32m    213\u001b[0m     \u001b[39mdel\u001b[39;00m exception, replace_context, from_, with_traceback\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1819\u001b[0m, in \u001b[0;36mConnection._execute_context\u001b[1;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[0;32m   1817\u001b[0m                 \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m   1818\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m evt_handled:\n\u001b[1;32m-> 1819\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdialect\u001b[39m.\u001b[39mdo_execute(\n\u001b[0;32m   1820\u001b[0m             cursor, statement, parameters, context\n\u001b[0;32m   1821\u001b[0m         )\n\u001b[0;32m   1823\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_events \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mengine\u001b[39m.\u001b[39m_has_events:\n\u001b[0;32m   1824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch\u001b[39m.\u001b[39mafter_cursor_execute(\n\u001b[0;32m   1825\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[0;32m   1826\u001b[0m         cursor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1830\u001b[0m         context\u001b[39m.\u001b[39mexecutemany,\n\u001b[0;32m   1831\u001b[0m     )\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\sqlalchemy\\engine\\default.py:732\u001b[0m, in \u001b[0;36mDefaultDialect.do_execute\u001b[1;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[0;32m    731\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdo_execute\u001b[39m(\u001b[39mself\u001b[39m, cursor, statement, parameters, context\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m--> 732\u001b[0m     cursor\u001b[39m.\u001b[39mexecute(statement, parameters)\n",
      "\u001b[1;31mProgrammingError\u001b[0m: (pyodbc.ProgrammingError) ('The SQL contains 0 parameter markers, but 1 parameters were supplied', 'HY000')\n[SQL: \n            UPDATE GENERAL.Developer_Dictionary\n            SET Cleaned_Developer = :cleaned_dev,\n                Last_Update = :last_update\n            WHERE Raw_Developer = :raw_dev AND Sector = :sector\n        ]\n[parameters: {'cleaned_dev': '379 Urban Development', 'last_update': '2023-12-06 16:43:44.934', 'raw_dev': '379 Urban Development Ltd.', 'sector': 'Main Sector'}]\n(Background on this error at: https://sqlalche.me/e/14/f405)"
     ]
    }
   ],
   "source": [
    "columns_that_need_unidecode = ['Cleaned_Developer']\n",
    "\n",
    "# Define SQL Server connection details\n",
    "engine = create_engine(cnt_str, pool_size=10, max_overflow=20)\n",
    "\n",
    "# Iterate over URLs\n",
    "for file_url in tqdm(url):\n",
    "    data = get_data(relative_url, file_url)\n",
    "    data = remove_unformated_character(data)\n",
    "    data = pd.DataFrame(data)\n",
    "    \n",
    "    # Iterate over columns that need unidecode\n",
    "    for i in columns_that_need_unidecode:\n",
    "        data[i] = remove_unicode(data[i])\n",
    "\n",
    "    today = pd.to_datetime('today').strftime(\"%Y-%m-%d %H:%M:%S.%f\")[:-3]\n",
    "    new_row = data[data['Update_Developer'].notnull()]\n",
    "    new_row['Cleaned_Developer'] = new_row['Update_Developer']\n",
    "    new_row['Last_Update'] = today\n",
    "\n",
    "    # Iterate over rows in the new_row DataFrame and update the database\n",
    "    for index, row in new_row.iterrows():\n",
    "        sql_query = \"\"\"\n",
    "            UPDATE GENERAL.Developer_Dictionary\n",
    "            SET Cleaned_Developer = :cleaned_dev,\n",
    "                Last_Update = :last_update\n",
    "            WHERE Raw_Developer = :raw_dev AND Sector = :sector\n",
    "        \"\"\"\n",
    "\n",
    "        # Execute the query with the row values using parameterized query\n",
    "        with engine.connect() as conn:\n",
    "            conn.execute(sql_query, cleaned_dev=row['Cleaned_Developer'],\n",
    "                                   last_update=today,\n",
    "                                   raw_dev=row['Raw_Developer'],\n",
    "                                   sector=row['Sector'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
