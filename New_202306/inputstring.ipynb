{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "378258c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from office365.runtime.auth.authentication_context import AuthenticationContext\n",
    "from office365.sharepoint.client_context import ClientContext\n",
    "from office365.sharepoint.files.file import File\n",
    "from office365.runtime.auth.client_credential import ClientCredential\n",
    "from office365.runtime.client_request_exception import ClientRequestException\n",
    "from datetime import *\n",
    "import pytz\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import glob\n",
    "import pyodbc\n",
    "import os \n",
    "import json\n",
    "from io import BytesIO\n",
    "import io\n",
    "import platform\n",
    "from function.PyToSp import *\n",
    "from tqdm import tqdm\n",
    "from urllib.parse import quote_plus\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, event,text\n",
    "import pyodbc\n",
    "import requests\n",
    "import inspect\n",
    "from validate import *\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "from urllib.parse import quote_plus\n",
    "import msal\n",
    "from itertools import chain\n",
    "from send_email import *\n",
    "import re\n",
    "# set to_email\n",
    "to_email = ['nthieu@savills.com.vn','pthihuongnguyen@savills.com.vn']\n",
    "# to_email = ['nthieu@savills.com.vn']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d8bee114",
   "metadata": {},
   "source": [
    "### CONNECT TO AZURE SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a39960d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONNECTION SUCESSFUL!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "f = open ('database_information.json', \"r\")\n",
    "qq = json.loads(f.read())\n",
    "f.close()\n",
    "ini_cnt_str ='Driver={driver_str};Server=tcp:hkazdevsqld3vnreserch.database.windows.net,1433;database={database};Uid={username};Pwd={password};Encrypt=yes;Authentication=ActiveDirectoryPassword;Connection Timeout=30;'.format(**qq)\n",
    "quoted = quote_plus(ini_cnt_str)\n",
    "cnt_str = 'mssql+pyodbc:///?odbc_connect={}'.format(quoted)\n",
    "engine = create_engine(cnt_str)\n",
    "\n",
    "#Test Connection\n",
    "try:\n",
    "    conn = engine.connect()\n",
    "    result = conn.execute(text(\"SELECT 1\"))\n",
    "    print(\"CONNECTION SUCESSFUL!\")\n",
    "except Exception as e:\n",
    "    print(\"CONNECTION FAILED:\",str(e))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "81420039",
   "metadata": {},
   "source": [
    "### CONNECT TO SHAREPOINT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b0587ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConnectSharePoint(url_hub):\n",
    "    header_Hub = f\"share_point_{url_hub.split('/')[2].replace('-','')}\"\n",
    "    config_Hub = read_config_json(config_path, header_Hub)\n",
    "    Hub = SharePoint(config_Hub)\n",
    "    #Hub.check_connect()\n",
    "    return Hub"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0e642c12",
   "metadata": {},
   "source": [
    "### READ AND LIST FOLDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d951e70e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder name: /sites/BIHub/Shared Documents/Advisory Data/IP/Flat file/Tien Giang Province\n",
      "/sites/BIHub/Shared Documents/Advisory Data/IP/Flat file/Nam Dinh Province\n",
      "/sites/BIHub/Shared Documents/Advisory Data/IP/Flat file/Vinh Phuc Province\n",
      "/sites/BIHub/Shared Documents/Advisory Data/IP/Flat file/Hai Duong Province\n",
      "/sites/BIHub/Shared Documents/Advisory Data/IP/Flat file/Binh Duong Province\n",
      "/sites/BIHub/Shared Documents/Advisory Data/IP/Flat file/Quang Nam Province\n",
      "/sites/BIHub/Shared Documents/Advisory Data/IP/Flat file/Ninh Binh Province\n",
      "/sites/BIHub/Shared Documents/Advisory Data/IP/Flat file/Thai Nguyen Province\n",
      "/sites/BIHub/Shared Documents/Advisory Data/IP/Flat file/Nghe An Province\n",
      "/sites/BIHub/Shared Documents/Advisory Data/IP/Flat file/Dong Nai Province\n",
      "/sites/BIHub/Shared Documents/Advisory Data/IP/Flat file/Quang Ngai Province\n",
      "/sites/BIHub/Shared Documents/Advisory Data/IP/Flat file/Da Nang City\n",
      "/sites/BIHub/Shared Documents/Advisory Data/IP/Flat file/Thai Binh Province\n",
      "/sites/BIHub/Shared Documents/Advisory Data/IP/Flat file/BRVT\n",
      "/sites/BIHub/Shared Documents/Advisory Data/IP/Flat file/Hoa Binh Province\n",
      "/sites/BIHub/Shared Documents/Advisory Data/IP/Flat file/Ho Chi Minh City\n",
      "/sites/BIHub/Shared Documents/Advisory Data/IP/Flat file/Thanh Hoa Province\n",
      "/sites/BIHub/Shared Documents/Advisory Data/IP/Flat file/Ha Nam Province\n",
      "/sites/BIHub/Shared Documents/Advisory Data/IP/Flat file/Binh Phuoc Province\n",
      "/sites/BIHub/Shared Documents/Advisory Data/IP/Flat file/Phu Tho Province\n",
      "/sites/BIHub/Shared Documents/Advisory Data/IP/Flat file/Hai Phong City\n",
      "/sites/BIHub/Shared Documents/Advisory Data/IP/Flat file/Ha Noi City\n",
      "/sites/BIHub/Shared Documents/Advisory Data/IP/Flat file/Long An Province\n",
      "/sites/BIHub/Shared Documents/Advisory Data/IP/Flat file/Quang Tri Province\n",
      "/sites/BIHub/Shared Documents/Advisory Data/IP/Flat file/Binh Thuan Province\n",
      "/sites/BIHub/Shared Documents/Advisory Data/IP/Flat file/Tay Ninh Province\n",
      "/sites/BIHub/Shared Documents/Advisory Data/IP/Flat file/Bac Ninh Province\n",
      "/sites/BIHub/Shared Documents/Advisory Data/IP/Flat file/Hung Yen Province\n",
      "/sites/BIHub/Shared Documents/Advisory Data/IP/Flat file/Bac Giang Province\n",
      "/sites/BIHub/Shared Documents/Advisory Data/IP/Flat file/Can Tho Province\n",
      "/sites/BIHub/Shared Documents/Advisory Data/IP/Flat file/Thua Thien Hue Province\n",
      "/sites/BIHub/Shared Documents/Advisory Data/IP/Flat file/Quang Ninh Province\n"
     ]
    }
   ],
   "source": [
    "#Tất cả các tỉnh\n",
    "relative_url = \"/sites/BIHub/Shared Documents/Advisory Data/IP/Flat file\"\n",
    "sp_object = relative_url.split('/')[2].replace('-','')\n",
    "list_folder = ConnectSharePoint(relative_url).get_content_url(relative_url,return_list_folder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def GetProvinceIS(provinces, list_folder):  \n",
    "        selected_provinces = []\n",
    "        province_list = []\n",
    "        for i in list_folder:\n",
    "            province_list.append(i.split('/')[7])\n",
    "        for input_province in provinces:\n",
    "            input_province = input_province.strip().lower()\n",
    "            if input_province == \"-1\":\n",
    "                break\n",
    "\n",
    "            matched_provinces = [province for province in province_list if input_province in province.lower()]\n",
    "            if matched_provinces:\n",
    "                selected_provinces.extend(matched_provinces)\n",
    "            else:\n",
    "                print(f\"Không tìm thấy tỉnh chứa từ khóa '{input_province}'.\")\n",
    "        return selected_provinces "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "34c9e135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IP_Bac Giang_20171231.xlsx;IP_Bac Giang_20181231.xlsx;IP_Bac Giang_20191231.xlsx;IP_Bac Giang_20201231.xlsx;IP_Bac Giang_20211231.xlsx;IP_Bac Giang_20220630.xlsx;IP_Bac Ninh_20220331.xlsx;IP_Bac Ninh_20230331.xlsx;IP_Bac Ninh_20201231.xlsx;IP_Bac Ninh_20220930.xlsx; IP_Bac Ninh_20220630.xlsx; IP_Bac Ninh_20220331.xlsx;IP_Bac Ninh_20191231.xlsx\n"
     ]
    }
   ],
   "source": [
    "\n",
    "str= input(f\"Nhap chuoi cac file muon import: \")\n",
    "# Remove punctuation after \".xlsx\" and before sector (IP or Macro)\n",
    "str = re.sub(r'(?<=\\.xlsx)[^;]+?(?=IP|Macro)', '', str)\n",
    "\n",
    "# Add semicolon (;) after each \".xlsx\" extension\n",
    "str = re.sub(r'(?<=\\.xlsx)', ';', str)\n",
    "\n",
    "# Replace multiple consecutive semicolons with a single semicolon\n",
    "str = re.sub(r';+', ';', str)\n",
    "\n",
    "# Remove any trailing semicolon at the end of the string\n",
    "str = str.rstrip(';')\n",
    "print(str)\n",
    "# # Split the string by semicolon\n",
    "# file_names = str.split(';')\n",
    "# sectors = []\n",
    "# provinces = []\n",
    "# dates = []\n",
    "# for file_name in file_names:\n",
    "# # Remove leading/trailing whitespaces\n",
    "#     file_name = file_name.strip()\n",
    "\n",
    "#     # Extract sector, province, and date\n",
    "#     sector, province, date_ext = file_name.split('_')\n",
    "\n",
    "#     # Extract date without extension\n",
    "#     date = os.path.splitext(date_ext)[0]\n",
    "\n",
    "#     # Append values to respective arrays\n",
    "#     if (sector == 'Macro'):\n",
    "#         sectors.append(f'{sector} economic')\n",
    "#     else: \n",
    "#         sectors.append(sector)\n",
    "#     provinces.append(province)\n",
    "#     dates.append(date)\n",
    "# quarters = []\n",
    "# years = []\n",
    "# for date in dates:\n",
    "#     year = int(date[:4])\n",
    "#     month = int(date[4:6])\n",
    "#     day = int(date[6:])\n",
    "#     years.append(year)\n",
    "#     # Determine the last day of the quarter\n",
    "#     if month in [3]:\n",
    "#         quarter = 'Q1'\n",
    "#     elif month in [6]:\n",
    "#         quarter = 'Q2'\n",
    "#     elif month in [9]:\n",
    "#         quarter = 'Q3'\n",
    "#     else:\n",
    "#         quarter = 'Q4'\n",
    "#     quarters.append(quarter)\n",
    "# selected_year_quarter = []\n",
    "# url_hub = []\n",
    "# Hub = []\n",
    "# list_folder =[]\n",
    "# for item in range (len(sectors)):\n",
    "#     url_hub.append(f'/sites/BIHub/Shared Documents/Advisory Data/{sectors[item]}/Flat file')\n",
    "#     Hub.append(ConnectSharePoint(url_hub[item]))\n",
    "#     list_folder.append(Hub[item].get_content_url(url_hub[item], return_list_folder=True))\n",
    "#     selected_provinces = GetProvinceIS(provinces, list_folder[item])\n",
    "#     folder_sub2 = f\"{url_hub[item]}/{selected_provinces[item]}/{years[item]}/{quarters[item]}\"\n",
    "#     selected_year_quarter.append(folder_sub2)\n",
    "# df_summ_file = pd.DataFrame({'Name':[],'ServerRelativeUrl':[], 'TimeLastModified':[], 'ModTime':[], 'Modified_by_ID':[]})\n",
    "# for i, url in enumerate(selected_year_quarter):\n",
    "#     df_summ_file = pd.concat([df_summ_file, Hub[i].get_content_url(url)])\n",
    "# list_url = df_summ_file['ServerRelativeUrl'].to_list()\n",
    "# url = []\n",
    "# for i in list_url:\n",
    "#     sector = i.split('/')[-1].split('_')[0].upper()\n",
    "#     if sector not in ('x'):\n",
    "#         url.append(i)\n",
    "#     else:\n",
    "#         pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fef49fa9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dates' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m quarters \u001b[39m=\u001b[39m []\n\u001b[0;32m      2\u001b[0m years \u001b[39m=\u001b[39m []\n\u001b[1;32m----> 3\u001b[0m \u001b[39mfor\u001b[39;00m date \u001b[39min\u001b[39;00m dates:\n\u001b[0;32m      4\u001b[0m     year \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(date[:\u001b[39m4\u001b[39m])\n\u001b[0;32m      5\u001b[0m     month \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(date[\u001b[39m4\u001b[39m:\u001b[39m6\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dates' is not defined"
     ]
    }
   ],
   "source": [
    "quarters = []\n",
    "years = []\n",
    "for date in dates:\n",
    "    year = int(date[:4])\n",
    "    month = int(date[4:6])\n",
    "    day = int(date[6:])\n",
    "    years.append(year)\n",
    "    # Determine the last day of the quarter\n",
    "    if month in [3]:\n",
    "        quarter = 'Q1'\n",
    "    elif month in [6]:\n",
    "        quarter = 'Q2'\n",
    "    elif month in [9]:\n",
    "        quarter = 'Q3'\n",
    "    else:\n",
    "        quarter = 'Q4'\n",
    "    quarters.append(quarter)\n",
    "print(years, quarters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41e195b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/sites/BIHub/Shared Documents/Advisory Data/IP/Flat file/Bac Ninh Province/2023/Q1\n",
      "Folder name: \n",
      "Files name: /sites/BIHub/Shared Documents/Advisory Data/IP/Flat file/Bac Ninh Province/2023/Q1/IP_BacNinh_20230331.xlsx\n"
     ]
    }
   ],
   "source": [
    "selected_year_quarter = []\n",
    "for item in range (len(sectors)):\n",
    "    url_hub=f'/sites/BIHub/Shared Documents/Advisory Data/{sectors[item]}/Flat file' \n",
    "    folder_sub2 = f\"{url_hub}/{selected_provinces[item]}/{years[item]}/{quarters[item]}\"\n",
    "    selected_year_quarter.append(folder_sub2)\n",
    "    print(selected_year_quarter[item])\n",
    "    # In danh sách các folder đã tìm thấy\n",
    "df_summ_file = pd.DataFrame({'Name':[],'ServerRelativeUrl':[], 'TimeLastModified':[], 'ModTime':[], 'Modified_by_ID':[]})\n",
    "for i in selected_year_quarter:\n",
    "    df_summ_file = pd.concat([df_summ_file, eval(sp_object).get_content_url(i)])\n",
    "list_url = df_summ_file['ServerRelativeUrl'].to_list()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "afbe169c",
   "metadata": {},
   "source": [
    "### GET IMPORT FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0b2498",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/sites/BIHub/Shared Documents/Advisory Data/IP/Flat file/Bac Ninh Province/2023/Q1/IP_BacNinh_20230331.xlsx']"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = []\n",
    "for i in list_url:\n",
    "    sector = i.split('/')[-1].split('_')[0].upper()\n",
    "    if sector not in ('x'):\n",
    "        url.append(i)\n",
    "    else:\n",
    "        pass\n",
    "url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1ca91b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e6cc61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['/sites/BIHub/Shared Documents/Advisory Data/IP/Flat file/Tien Giang Province', '/sites/BIHub/Shared Documents/Advisory Data/IP/Flat file/Nam Dinh Province', '/sites/BIHub/Shared Documents/Advisory Data/IP/Flat file/Vinh Phuc Province', '/sites/BIHub/Shared Documents/Advisory Data/IP/Flat file/Hai Duong Province', '/sites/BIHub/Shared Documents/Advisory Data/IP/Flat file/Binh Duong Province', '/sites/BIHub/Shared Documents/Advisory Data/IP/Flat file/Quang Nam Province', '/sites/BIHub/Shared Documents/Advisory Data/IP/Flat file/Ninh Binh Province', '/sites/BIHub/Shared Documents/Advisory Data/IP/Flat file/Thai Nguyen Province', '/sites/BIHub/Shared Documents/Advisory Data/IP/Flat file/Nghe An Province', '/sites/BIHub/Shared Documents/Advisory Data/IP/Flat file/Dong Nai Province', '/sites/BIHub/Shared Documents/Advisory Data/IP/Flat file/Quang Ngai Province', '/sites/BIHub/Shared Documents/Advisory Data/IP/Flat file/Da Nang City', '/sites/BIHub/Shared Documents/Advisory Data/IP/Flat file/Thai Binh Province', '/sites/BIHub/Shared Documents/Advisory Data/IP/Flat file/BRVT', '/sites/BIHub/Shared Documents/Advisory Data/IP/Flat file/Hoa Binh Province', '/sites/BIHub/Shared Documents/Advisory Data/IP/Flat file/Ho Chi Minh City', '/sites/BIHub/Shared Documents/Advisory Data/IP/Flat file/Thanh Hoa Province', '/sites/BIHub/Shared Documents/Advisory Data/IP/Flat file/Ha Nam Province', '/sites/BIHub/Shared Documents/Advisory Data/IP/Flat file/Binh Phuoc Province', '/sites/BIHub/Shared Documents/Advisory Data/IP/Flat file/Phu Tho Province', '/sites/BIHub/Shared Documents/Advisory Data/IP/Flat file/Hai Phong City', '/sites/BIHub/Shared Documents/Advisory Data/IP/Flat file/Ha Noi City', '/sites/BIHub/Shared Documents/Advisory Data/IP/Flat file/Long An Province', '/sites/BIHub/Shared Documents/Advisory Data/IP/Flat file/Quang Tri Province', '/sites/BIHub/Shared Documents/Advisory Data/IP/Flat file/Binh Thuan Province', '/sites/BIHub/Shared Documents/Advisory Data/IP/Flat file/Tay Ninh Province', '/sites/BIHub/Shared Documents/Advisory Data/IP/Flat file/Bac Ninh Province', '/sites/BIHub/Shared Documents/Advisory Data/IP/Flat file/Hung Yen Province', '/sites/BIHub/Shared Documents/Advisory Data/IP/Flat file/Bac Giang Province', '/sites/BIHub/Shared Documents/Advisory Data/IP/Flat file/Can Tho Province', '/sites/BIHub/Shared Documents/Advisory Data/IP/Flat file/Thua Thien Hue Province', '/sites/BIHub/Shared Documents/Advisory Data/IP/Flat file/Quang Ninh Province']] /sites/BIHub/Shared Documents/Advisory Data/IP/Flat file ['/sites/BIHub/Shared Documents/Advisory Data/IP/Flat file/Bac Ninh Province/2023/Q1/IP_BacNinh_20230331.xlsx'] ['nthieu@savills.com.vn', 'pthihuongnguyen@savills.com.vn'] ['Project_Name', 'Sub_Project_Name', 'Developer_Name', 'City', 'District', 'Target_Industry'] mssql+pyodbc:///?odbc_connect=Driver%3DODBC+Driver+17+for+SQL+Server%3BServer%3Dtcp%3Ahkazdevsqld3vnreserch.database.windows.net%2C1433%3Bdatabase%3DD3VNResearch_Staging%3BUid%3DD3VNResearch%40savills.com.vn%3BPwd%3D%40Advisory052023%21%3BEncrypt%3Dyes%3BAuthentication%3DActiveDirectoryPassword%3BConnection+Timeout%3D30%3B Engine(mssql+pyodbc:///?odbc_connect=Driver%3DODBC+Driver+17+for+SQL+Server%3BServer%3Dtcp%3Ahkazdevsqld3vnreserch.database.windows.net%2C1433%3Bdatabase%3DD3VNResearch_Staging%3BUid%3DD3VNResearch%40savills.com.vn%3BPwd%3D%40Advisory052023%21%3BEncrypt%3Dyes%3BAuthentication%3DActiveDirectoryPassword%3BConnection+Timeout%3D30%3B) BIHub                        Name  \\\n",
      "0  IP_BacNinh_20230331.xlsx   \n",
      "\n",
      "                                   ServerRelativeUrl      TimeLastModified  \\\n",
      "0  /sites/BIHub/Shared Documents/Advisory Data/IP...  2023-06-26T07:40:34Z   \n",
      "\n",
      "              ModTime  Modified_by_ID  \n",
      "0 2023-06-26 07:40:34          1580.0   [<function.PyToSp.SharePoint object at 0x000001A45F228A30>]\n"
     ]
    }
   ],
   "source": [
    "columns_that_need_unidecode=['Project_Name', 'Sub_Project_Name', 'Developer_Name'\n",
    "                             , 'City', 'District', 'Target_Industry']\n",
    "print(list_folder, url_hub, list_url, to_email, columns_that_need_unidecode,cnt_str, engine, sp_object,df_summ_file, Hub)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "df571cf7",
   "metadata": {},
   "source": [
    "### IMPORT DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa7bc94",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Get Data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mMore than two 'Date_Key' in IP_BacNinh_20230331\u001b[0m\n",
      "Start Check duplicate sub_name...\n",
      "Start validation step...\n",
      "Start Check dictionary...\n",
      "Start checking dictionary of [City:City]...\n",
      "Start checking dictionary of [District:District]...\n",
      "Start checking dictionary of [Status:Status]...\n",
      "Start checking dictionary of [Project_Sub_Type:Sub_Type]...\n",
      "Start checking dictionary of [Project_Type:Type]...\n",
      "End Check dictionary with df_dict = 0 ...\n",
      "\u001b[32mValidate succesfully\u001b[0m\n",
      "CONNECTION SUCESSFUL IN INSERT TO FRESH FUNCTION!\n",
      "Insert IP_BacNinh_20230331 to Fresh\n",
      "Insert IP_BacNinh_20230331 to Fresh\n",
      "Insert IP_BacNinh_20230331 to Fresh\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:18<00:00, 18.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32minsert_to_fresh SUCESSFUL!\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "'''Prepare ingredients''' \n",
    "columns_that_need_unidecode=['Project_Name', 'Sub_Project_Name', 'Developer_Name'\n",
    "                             , 'City', 'District', 'Target_Industry']\n",
    "#Create empty df for checking dictionary\n",
    "df_dict = pd.DataFrame(columns=['File_Name', 'Missing_Values', 'Flag'])\n",
    "#Create multi empty df for tracking autdit step\n",
    "name_sector = ['IP']\n",
    "name_sector = [x.lower() for x in name_sector]\n",
    "for i in name_sector:\n",
    "    globals()['df_temp_flat_{}'.format(i)] = pd.DataFrame([])\n",
    "    globals()['df_flat_{}'.format(i)] = pd.DataFrame([])\n",
    "    globals()['df_new_key_{}'.format(i)] = pd.DataFrame([])  \n",
    "#-------------------------------------------------------\n",
    "'''Get data''' \n",
    "print('Start Get Data...')\n",
    "for file_url in tqdm(url):  \n",
    "    data, file_name, sector = get_data(relative_url, file_url)\n",
    "    #-------------------------------------------------------\n",
    "    data = check_date_key(file_url, data)#Check format date_key in flat file   \n",
    "    data['Project_Name']= np.where(data['Project_Name'].isnull(), data['Sub_Project_Name'], data['Project_Name'])#Fill up project_name if its null\n",
    "    data['Project_Sub_Type']= np.where(data['Project_Sub_Type'].isnull(), data['Project_Type'], data['Project_Sub_Type'])#Fill up Sub_Type if its null\n",
    "    \n",
    "    #Check duplicate sub_name\n",
    "    print('Start Check duplicate sub_name...')\n",
    "    data, df_dup = check_duplicate(data, 'Sub_Project_Name')\n",
    "    if len(df_dup) != 0:\n",
    "        print(colored('Check duplicate sub_name', 'yellow'))\n",
    "        df_noti_html = convert_df_to_html(type_html = 1, df = df_dup, type_sector = 2, cnxn = engine)\n",
    "        run_email(type_sector = 'IP', email_type = 1, user_email = to_email, df_noti_html = df_noti_html)\n",
    "    else:       \n",
    "        #-------------------------------------------------------\n",
    "        \n",
    "        '''Validation step'''\n",
    "        print('Start validation step...')\n",
    "        #Remove unfortmated values\n",
    "        data = remove_unformated_character(data)\n",
    "        #Remove unicode characters\n",
    "        for i in columns_that_need_unidecode:\n",
    "            data[i] = remove_unicode(data[i])\n",
    "        #Check dictionary\n",
    "        print('Start Check dictionary...')\n",
    "        lst_dict = ['City', 'District', 'Status', 'Sub_Type', 'Type']\n",
    "        lst_cls = ['City', 'District', 'Status', 'Project_Sub_Type', 'Project_Type']\n",
    "        for i, j in zip(lst_cls, lst_dict):\n",
    "            print(f'Start checking dictionary of [{i}:{j}]...')\n",
    "            data, df_dict = check_dictionary(df_dict, file_name, data, i, j, sector, engine, sp_object)\n",
    "        print(f'End Check dictionary with df_dict = {len(df_dict)} ...')\n",
    "        \n",
    "        if len(df_dict) == 0:\n",
    "            print(colored('Validate succesfully','green'))\n",
    "            #-------------------------------------------------------\n",
    "            '''Import data process'''\n",
    "            #Check project key\n",
    "            data = Generate_Additional_Columns(data,url,df_summ_file,BIHub,engine,file_url)\n",
    "            processed_data, flag_key = check_project_key(file_url, data, sector, engine)\n",
    "            df_temp_flat_ip = pd.concat([df_temp_flat_ip, data], axis=0)\n",
    "            df_flat_ip = tracking_flat_file(df_temp_flat_ip, file_url)\n",
    "            if len(processed_data) != 0:\n",
    "                df_new_key_ip = check_new_key(df_new_key = df_new_key_ip, processed_data = processed_data, sector = sector)\n",
    "            #Get key and generate new key (if needed)\n",
    "            data = get_project_key(flag_key, processed_data, data, sector, engine)\n",
    "            # insert_to_fresh(file_url, data, cnt_str)\n",
    "        \n",
    "            \n",
    "            #Test insert_to_fresh\n",
    "            try:\n",
    "                result = insert_to_fresh(file_url, data, cnt_str)\n",
    "                print(colored(\"insert_to_fresh SUCESSFUL!\",'green'))\n",
    "            except Exception as e:\n",
    "                print(colored(\"insert_to_fresh FAILED:\",str(e),'red'))\n",
    "            \n",
    "        else:\n",
    "            print(df_dict)\n",
    "            print(colored('Validate failed','red'))\n",
    "            pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b005d5eb",
   "metadata": {},
   "source": [
    "### SEND EMAIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b12652",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "list_df_flat = [df_flat_ip]\n",
    "list_df_new_key = [df_new_key_ip]\n",
    "#Email notify missing in dictionary\n",
    "if len(df_dict) != 0:\n",
    "    print(colored('Missing values in dictionary','yellow'))\n",
    "    df_noti_html = convert_df_to_html(type_html = 2, df = df_dict, cnxn = engine)\n",
    "    run_email(email_type = 2, user_email = to_email, df_noti_html = df_noti_html)\n",
    "else:\n",
    "    pass\n",
    "\n",
    "#Email notify imported data\n",
    "df_flat_html, df_query_html = convert_df_to_html(type_html = 3, list_df = list_df_flat, type_sector = 2, cnxn = engine)\n",
    "run_email(type_sector = 'IP', email_type = 3, user_email = to_email, df_flat_html = df_flat_html, df_query_html = df_query_html)\n",
    "\n",
    "#Email notify create new key\n",
    "df_new_key_html = convert_df_to_html(type_html = 4, list_df = list_df_new_key, cnxn = engine)\n",
    "if len(df_new_key_html) != 0:\n",
    "    print(colored('Some new keys were created','yellow'))\n",
    "    run_email(type_sector = 'IP', email_type = 4, user_email = to_email, df_noti_html = df_new_key_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0a281d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2e64df76",
   "metadata": {},
   "source": [
    "### TRACKING AUDIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6edb6c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "insert_to_tracking(list_df_flat, 'Tracking_IP', engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6808d09b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
