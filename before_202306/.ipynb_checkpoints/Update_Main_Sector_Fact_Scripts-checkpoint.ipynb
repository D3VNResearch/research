{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12012f35",
   "metadata": {},
   "source": [
    "### IMPORT LIBRARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "378258c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from office365.runtime.auth.authentication_context import AuthenticationContext\n",
    "from office365.sharepoint.client_context import ClientContext\n",
    "from office365.sharepoint.files.file import File\n",
    "from office365.runtime.auth.client_credential import ClientCredential\n",
    "from office365.runtime.client_request_exception import ClientRequestException\n",
    "import datetime\n",
    "import pytz\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import glob\n",
    "import pyodbc\n",
    "import os \n",
    "import json\n",
    "from io import BytesIO\n",
    "import io\n",
    "import platform\n",
    "from function.PyToSp import *\n",
    "from tqdm import tqdm\n",
    "from urllib.parse import quote_plus\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, event\n",
    "import pyodbc\n",
    "import requests\n",
    "import inspect\n",
    "from validate_update import *\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "from urllib.parse import quote_plus\n",
    "import msal\n",
    "from itertools import chain\n",
    "from termcolor import colored\n",
    "from send_email import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8bee114",
   "metadata": {},
   "source": [
    "### CONNECT TO AZURE SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a39960d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONNECTION FAILED: 'Engine' object has no attribute 'execute'\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "f = open ('database_information.json', \"r\")\n",
    "qq = json.loads(f.read())\n",
    "f.close()\n",
    "ini_cnt_str ='Driver={driver_str};Server=tcp:hkazdevsqld3vnreserch.database.windows.net,1433;database={database};Uid={username};Pwd={password};Encrypt=yes;Authentication=ActiveDirectoryPassword;Connection Timeout=30;'.format(**qq)\n",
    "quoted = quote_plus(ini_cnt_str)\n",
    "cnt_str = 'mssql+pyodbc:///?odbc_connect={}'.format(quoted)\n",
    "engine = create_engine(cnt_str)\n",
    "\n",
    "#Test ConnectionD\n",
    "try:\n",
    "    result = engine.execute(\"SELECT 1\")\n",
    "    print(\"CONNECTION SUCESSFUL!\")\n",
    "except Exception as e:\n",
    "    print(\"CONNECTION FAILED:\",str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81420039",
   "metadata": {},
   "source": [
    "### CONNECT TO SHAREPOINT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b0587ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Web site title: S22M Research & BI Hub _ Successful Connection!\n"
     ]
    }
   ],
   "source": [
    "header_BIHub = 'share_point_BIHub'\n",
    "config_BIHub = read_config_json(config_path, header_BIHub)\n",
    "BIHub = SharePoint(config_BIHub)\n",
    "BIHub.check_connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e642c12",
   "metadata": {},
   "source": [
    "### READ AND LIST FOLDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d951e70e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder name: /sites/BIHub/Shared Documents/Advisory Data/Main sector/Update/Fact/Binh Duong Province\n",
      "/sites/BIHub/Shared Documents/Advisory Data/Main sector/Update/Fact/Ha Noi City\n",
      "/sites/BIHub/Shared Documents/Advisory Data/Main sector/Update/Fact/Ho Chi Minh City\n"
     ]
    }
   ],
   "source": [
    "#Tất cả các tỉnh\n",
    "relative_url = \"/sites/BIHub/Shared Documents/Advisory Data/Main sector/Update/Fact\"\n",
    "sp_object = relative_url.split('/')[2].replace('-','')\n",
    "list_folder = eval(sp_object).get_content_url(relative_url,return_list_folder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "162f57a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder name: /sites/BIHub/Shared Documents/Advisory Data/Main sector/Update/Fact/Binh Duong Province/2023\n",
      "Folder name: /sites/BIHub/Shared Documents/Advisory Data/Main sector/Update/Fact/Ha Noi City/2022\n",
      "Folder name: /sites/BIHub/Shared Documents/Advisory Data/Main sector/Update/Fact/Ho Chi Minh City/2022\n",
      "/sites/BIHub/Shared Documents/Advisory Data/Main sector/Update/Fact/Ho Chi Minh City/2023\n"
     ]
    }
   ],
   "source": [
    "#lấy năm\n",
    "list_folder_sub1=[]\n",
    "for i in list_folder:\n",
    "    ls=eval(sp_object).get_content_url(i,return_list_folder=True)\n",
    "    list_folder_sub1=list_folder_sub1+ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "338da9f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder name: /sites/BIHub/Shared Documents/Advisory Data/Main sector/Update/Fact/Binh Duong Province/2023/Q1\n",
      "Folder name: /sites/BIHub/Shared Documents/Advisory Data/Main sector/Update/Fact/Ha Noi City/2022/Q4\n",
      "Folder name: /sites/BIHub/Shared Documents/Advisory Data/Main sector/Update/Fact/Ho Chi Minh City/2022/Q4\n",
      "Folder name: /sites/BIHub/Shared Documents/Advisory Data/Main sector/Update/Fact/Ho Chi Minh City/2023/Q1\n",
      "/sites/BIHub/Shared Documents/Advisory Data/Main sector/Update/Fact/Ho Chi Minh City/2023/Q2\n"
     ]
    }
   ],
   "source": [
    "#lấy quý\n",
    "list_folder_sub2=[]\n",
    "for i in list_folder_sub1:\n",
    "    ls=eval(sp_object).get_content_url(i,return_list_folder=True)\n",
    "    list_folder_sub2=list_folder_sub2+ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa46fe3c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/sites/BIHub/Shared Documents/Advisory Data/Main sector/Update/Fact/Binh Duong Province/2023/Q1\n",
      "/sites/BIHub/Shared Documents/Advisory Data/Main sector/Update/Fact/Ha Noi City/2022/Q4\n",
      "/sites/BIHub/Shared Documents/Advisory Data/Main sector/Update/Fact/Ho Chi Minh City/2022/Q4\n",
      "/sites/BIHub/Shared Documents/Advisory Data/Main sector/Update/Fact/Ho Chi Minh City/2023/Q1\n",
      "/sites/BIHub/Shared Documents/Advisory Data/Main sector/Update/Fact/Ho Chi Minh City/2023/Q2\n",
      "Folder name: \n",
      "Files name: /sites/BIHub/Shared Documents/Advisory Data/Main sector/Update/Fact/Ho Chi Minh City/2023/Q2/Update_VLTH_HCMC_20230630.xlsx\n",
      "Files name: /sites/BIHub/Shared Documents/Advisory Data/Main sector/Update/Fact/Ho Chi Minh City/2023/Q2/UPDATE_APT_HCMC_20230630.xlsx\n"
     ]
    }
   ],
   "source": [
    "#Provide information\n",
    "Province_name=['Ho Chi Minh City']#Chọn tỉnh cần import-- là tên folder \n",
    "Year=['2023']#Chọn năm cần import\n",
    "Quarter=['Q2']#Chọn quý cần import\n",
    "#Có thể chọn nhiều tỉnh, tên tỉnh để trong dấu nháy đơn và cách nhau bởi dấy phẩy. Áp dụng tương tự cho năm, quý\n",
    "#-------------------------------------------------------\n",
    "df_summ_file = pd.DataFrame({'Name':[],'ServerRelativeUrl':[], 'TimeLastModified':[], 'ModTime':[], 'Modified_by_ID':[]})\n",
    "for i in list_folder_sub2:\n",
    "    print(i)\n",
    "    if i.split('/')[-3] in Province_name and i.split('/')[-2] in Year and i.split('/')[-1] in Quarter:\n",
    "        df_summ_file = pd.concat([df_summ_file, eval(sp_object).get_content_url(i)])\n",
    "\n",
    "list_url = df_summ_file['ServerRelativeUrl'].to_list()\n",
    "#History file\n",
    "df_query=pd.DataFrame(df_summ_file).reset_index(drop=True)\n",
    "df_summ_file = df_summ_file.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbe169c",
   "metadata": {},
   "source": [
    "### GET IMPORT FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51e0061a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/sites/BIHub/Shared Documents/Advisory Data/Main sector/Update/Fact/Ho Chi Minh City/2023/Q2/Update_VLTH_HCMC_20230630.xlsx']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = []\n",
    "for i in list_url:\n",
    "    sector = i.split('/')[-1].split('_')[1].upper()\n",
    "    if sector in ('APT'): #Chọn sector cần import: RETAIL, OFFICE, SA, HOTEL, APT, VLTH\n",
    "        url.append(i)\n",
    "    else:\n",
    "        pass\n",
    "url"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df571cf7",
   "metadata": {},
   "source": [
    "### IMPORT DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5fa7bc94",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/1 [00:05<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'OptionEngine' object has no attribute 'execute'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 26\u001b[0m\n\u001b[0;32m     24\u001b[0m lst_cls \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProject_City_Name\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProject_District_Name\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSub_Project_Type\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGrade\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(lst_cls, lst_dict):\n\u001b[1;32m---> 26\u001b[0m     data, df_dict \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_dictionary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msp_object\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(df_dict) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;28mprint\u001b[39m(colored(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mValidate succesfully\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgreen\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "File \u001b[1;32mC:\\Project_Savills\\Code Cu~\\research\\before_202306\\validate_update.py:101\u001b[0m, in \u001b[0;36mcheck_dictionary\u001b[1;34m(df_dict, file_name, data, column_name, parameter, sector, cnxn, sp_object)\u001b[0m\n\u001b[0;32m     99\u001b[0m lower_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m parameter \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCity\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDistrict\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStatus\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIndicator\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m--> 101\u001b[0m     raw_parameter \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_sql\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mselect * from GENERAL.\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mparameter\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_Dictionary\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mcnxn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    102\u001b[0m     raw_parameter[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRaw_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparameter\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m raw_parameter[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRaw_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparameter\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(lower_function)\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m parameter \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGrade\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\pandas\\io\\sql.py:590\u001b[0m, in \u001b[0;36mread_sql\u001b[1;34m(sql, con, index_col, coerce_float, params, parse_dates, columns, chunksize)\u001b[0m\n\u001b[0;32m    581\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pandas_sql\u001b[38;5;241m.\u001b[39mread_table(\n\u001b[0;32m    582\u001b[0m         sql,\n\u001b[0;32m    583\u001b[0m         index_col\u001b[38;5;241m=\u001b[39mindex_col,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    587\u001b[0m         chunksize\u001b[38;5;241m=\u001b[39mchunksize,\n\u001b[0;32m    588\u001b[0m     )\n\u001b[0;32m    589\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 590\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpandas_sql\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_query\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    591\u001b[0m \u001b[43m        \u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    592\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    593\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    594\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcoerce_float\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcoerce_float\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    595\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    596\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    597\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\pandas\\io\\sql.py:1560\u001b[0m, in \u001b[0;36mSQLDatabase.read_query\u001b[1;34m(self, sql, index_col, coerce_float, parse_dates, params, chunksize, dtype)\u001b[0m\n\u001b[0;32m   1512\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1513\u001b[0m \u001b[38;5;124;03mRead SQL query into a DataFrame.\u001b[39;00m\n\u001b[0;32m   1514\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \n\u001b[0;32m   1557\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m args \u001b[38;5;241m=\u001b[39m _convert_params(sql, params)\n\u001b[1;32m-> 1560\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1561\u001b[0m columns \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mkeys()\n\u001b[0;32m   1563\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\pandas\\io\\sql.py:1405\u001b[0m, in \u001b[0;36mSQLDatabase.execute\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1403\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexecute\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   1404\u001b[0m     \u001b[38;5;124;03m\"\"\"Simple passthrough to SQLAlchemy connectable\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1405\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnectable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecution_options\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'OptionEngine' object has no attribute 'execute'"
     ]
    }
   ],
   "source": [
    "'''Prepare ingredients''' \n",
    "columns_that_need_unidecode = ['Sub_Project_Name', 'Project_City_Name', 'Project_District_Name']\n",
    "#Create empty df for checking dictionary\n",
    "df_dict = pd.DataFrame(columns=['File_Name', 'Missing_Values', 'Flag'])\n",
    "name_sector = ['RETAIL', 'SA', 'APT', 'VLTH', 'OFFICE', 'HOTEL']\n",
    "for i in name_sector:\n",
    "    globals()[f'df_update_{i.lower()}'] = pd.DataFrame([])\n",
    "    globals()[f'df_flat__{i.lower()}'] = pd.DataFrame([])\n",
    "#-------------------------------------------------------\n",
    "'''Get data''' \n",
    "for file_url in tqdm(url):\n",
    "    data, file_name, sector = get_data(relative_url, file_url)\n",
    "    # #-------------------------------------------------------\n",
    "\n",
    "    '''Validation step'''\n",
    "    #Remove unfortmated values\n",
    "    data = remove_unformated_character(data)\n",
    "\n",
    "    #Remove unicode characters\n",
    "    for i in columns_that_need_unidecode:\n",
    "        data[i] = remove_unicode(data[i])\n",
    "    #Check dictionary\n",
    "    lst_dict = ['City', 'District', 'Type', 'Grade']\n",
    "    lst_cls = ['Project_City_Name', 'Project_District_Name', 'Sub_Project_Type', 'Grade']\n",
    "    for i, j in zip(lst_cls, lst_dict):\n",
    "        data, df_dict = check_dictionary(df_dict, file_name, data, i, j, sector, engine, sp_object)\n",
    "    if len(df_dict) == 0:\n",
    "        print(colored('Validate succesfully','green'))\n",
    "        #-------------------------------------------------------\n",
    "        '''Import data process'''\n",
    "        #Check project key\n",
    "        processed_data, flag_key = check_project_key(file_url, data, sector, engine)\n",
    "        if flag_key == 0:\n",
    "            data = get_project_key(flag_key, processed_data, data, sector, engine)\n",
    "            if sector == 'RETAIL':\n",
    "                df_update_retail = pd.concat([df_update_retail, data], axis=0)\n",
    "                df_flat_retail = get_flat_file(df_update_retail, sector, engine)\n",
    "                flag_update, data = update_flat_file(sector, df_flat_retail, df_update_retail)\n",
    "            elif sector == 'OFFICE':\n",
    "                df_update_office = pd.concat([df_update_office, data], axis=0)\n",
    "                df_flat_office = get_flat_file(df_update_office, sector, engine)\n",
    "                flag_update, data = update_flat_file(sector, df_flat_office, df_update_office)\n",
    "            elif sector == 'HOTEL':\n",
    "                df_update_hotel = pd.concat([df_update_hotel, data], axis=0)\n",
    "                df_flat_hotel = get_flat_file(df_update_hotel, sector, engine)\n",
    "                flag_update, data = update_flat_file(sector, df_flat_hotel, df_update_hotel)\n",
    "            elif sector == 'SA' or sector=='SERVICED_APARTMENT':\n",
    "                df_update_sa = pd.concat([df_update_sa, data], axis=0)\n",
    "                df_flat_sa = get_flat_file(df_update_sa, sector, engine)\n",
    "                flag_update, data = update_flat_file(sector, df_flat_sa, df_update_sa)\n",
    "            elif sector == 'APT' or sector=='APARTMENT':\n",
    "                df_update_apt = pd.concat([df_update_apt, data], axis=0)\n",
    "                df_flat_apt = get_flat_file(df_update_apt, sector, engine)\n",
    "                flag_update, data = update_flat_file(sector, df_flat_apt, df_update_apt)\n",
    "            elif sector == 'VLTH':\n",
    "                df_update_vlth = pd.concat([df_update_vlth, data], axis=0)\n",
    "                df_flat_vlth = get_flat_file(df_update_vlth, sector, engine)\n",
    "                flag_update, data = update_flat_file(sector, df_flat_vlth, df_update_vlth)\n",
    "            #-------------------------------------------------------    \n",
    "            if flag_update == 0:\n",
    "                #insert_to_fresh(file_url, data, cnt_str)\n",
    "                list_df_update = [df_update_retail, df_update_office, df_update_hotel, df_update_sa, df_update_apt, df_update_vlth]\n",
    "                for df_update in list_df_update:\n",
    "                    if len(df_update) != 0:\n",
    "                        df_update = Generate_Additional_Columns(df_update,url,df_summ_file,BIHub,engine,file_url)\n",
    "                        insert_to_tracking(df_update, sector, engine)\n",
    "            else:\n",
    "                print(colored(f'Some keys wrong in {file_name}', 'yellow'))\n",
    "        else:\n",
    "            print(colored(f'Cant get key in {file_name}', 'yellow'))\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4174a392",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
