{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12012f35",
   "metadata": {},
   "source": [
    "### IMPORT LIBRARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "378258c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from office365.runtime.auth.authentication_context import AuthenticationContext\n",
    "from office365.sharepoint.client_context import ClientContext\n",
    "from office365.sharepoint.files.file import File\n",
    "from office365.runtime.auth.client_credential import ClientCredential\n",
    "from office365.runtime.client_request_exception import ClientRequestException\n",
    "import datetime\n",
    "import pytz\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import glob\n",
    "import pyodbc\n",
    "import os \n",
    "import json\n",
    "from io import BytesIO\n",
    "import io\n",
    "import platform\n",
    "from function.PyToSp import *\n",
    "from tqdm import tqdm\n",
    "from urllib.parse import quote_plus\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, event, text\n",
    "import pyodbc\n",
    "import requests\n",
    "import inspect\n",
    "from validate_update import *\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "from urllib.parse import quote_plus\n",
    "import msal\n",
    "from itertools import chain\n",
    "from termcolor import colored\n",
    "from send_email import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8bee114",
   "metadata": {},
   "source": [
    "### CONNECT TO AZURE SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a39960d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONNECTION SUCESSFUL!\n"
     ]
    }
   ],
   "source": [
    "def ConnectAzureSQLServer(): \n",
    "    f = open ('database_information.json', \"r\") #Database information file, can change information depending on the time\n",
    "    qq = json.loads(f.read())\n",
    "    f.close()\n",
    "    ini_cnt_str ='Driver={driver_str};Server=tcp:{servername},1433;database={database};Uid={username};Pwd={password};Encrypt=yes;Authentication=ActiveDirectoryPassword;Connection Timeout=30;'.format(**qq)\n",
    "    quoted = quote_plus(ini_cnt_str)\n",
    "    cnt_str = 'mssql+pyodbc:///?odbc_connect={}'.format(quoted)\n",
    "    engine = create_engine(cnt_str)\n",
    "\n",
    "        #Test Connection\n",
    "    try:\n",
    "        conn = engine.connect()\n",
    "        result = conn.execute(text(\"SELECT 1\"))\n",
    "        print(\"CONNECTION SUCESSFUL!\")\n",
    "    except Exception as e:\n",
    "        print(\"CONNECTION FAILED:\",str(e))\n",
    "    return cnt_str\n",
    "cnt_str = ConnectAzureSQLServer()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81420039",
   "metadata": {},
   "source": [
    "### CONNECT TO SHAREPOINT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b0587ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Web site title: S22M Research & BI Hub _ Successful Connection!\n"
     ]
    }
   ],
   "source": [
    "header_BIHub = 'share_point_BIHub'\n",
    "config_BIHub = read_config_json(config_path, header_BIHub)\n",
    "BIHub = SharePoint(config_BIHub)\n",
    "BIHub.check_connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e642c12",
   "metadata": {},
   "source": [
    "### READ AND LIST FOLDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d951e70e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder name: /sites/BIHub/Shared Documents/Advisory Data/Main sector/Update/Fact/Binh Duong Province\n",
      "/sites/BIHub/Shared Documents/Advisory Data/Main sector/Update/Fact/Ha Noi City\n",
      "/sites/BIHub/Shared Documents/Advisory Data/Main sector/Update/Fact/Ho Chi Minh City\n"
     ]
    }
   ],
   "source": [
    "#Tất cả các tỉnh\n",
    "relative_url = \"/sites/BIHub/Shared Documents/Advisory Data/Main sector/Update/Fact\"\n",
    "sp_object = relative_url.split('/')[2].replace('-','')\n",
    "list_folder = eval(sp_object).get_content_url(relative_url,return_list_folder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "162f57a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder name: /sites/BIHub/Shared Documents/Advisory Data/Main sector/Update/Fact/Binh Duong Province/2023\n",
      "Folder name: /sites/BIHub/Shared Documents/Advisory Data/Main sector/Update/Fact/Ha Noi City/2022\n",
      "Folder name: /sites/BIHub/Shared Documents/Advisory Data/Main sector/Update/Fact/Ho Chi Minh City/2022\n",
      "/sites/BIHub/Shared Documents/Advisory Data/Main sector/Update/Fact/Ho Chi Minh City/2023\n"
     ]
    }
   ],
   "source": [
    "#lấy năm\n",
    "list_folder_sub1=[]\n",
    "for i in list_folder:\n",
    "    ls=eval(sp_object).get_content_url(i,return_list_folder=True)\n",
    "    list_folder_sub1=list_folder_sub1+ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "338da9f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder name: /sites/BIHub/Shared Documents/Advisory Data/Main sector/Update/Fact/Binh Duong Province/2023/Q1\n",
      "Folder name: /sites/BIHub/Shared Documents/Advisory Data/Main sector/Update/Fact/Ha Noi City/2022/Q4\n",
      "Folder name: /sites/BIHub/Shared Documents/Advisory Data/Main sector/Update/Fact/Ho Chi Minh City/2022/Q4\n",
      "Folder name: /sites/BIHub/Shared Documents/Advisory Data/Main sector/Update/Fact/Ho Chi Minh City/2023/Q1\n",
      "/sites/BIHub/Shared Documents/Advisory Data/Main sector/Update/Fact/Ho Chi Minh City/2023/Q2\n"
     ]
    }
   ],
   "source": [
    "#lấy quý\n",
    "list_folder_sub2=[]\n",
    "for i in list_folder_sub1:\n",
    "    ls=eval(sp_object).get_content_url(i,return_list_folder=True)\n",
    "    list_folder_sub2=list_folder_sub2+ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa46fe3c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/sites/BIHub/Shared Documents/Advisory Data/Main sector/Update/Fact/Binh Duong Province/2023/Q1\n",
      "/sites/BIHub/Shared Documents/Advisory Data/Main sector/Update/Fact/Ha Noi City/2022/Q4\n",
      "/sites/BIHub/Shared Documents/Advisory Data/Main sector/Update/Fact/Ho Chi Minh City/2022/Q4\n",
      "/sites/BIHub/Shared Documents/Advisory Data/Main sector/Update/Fact/Ho Chi Minh City/2023/Q1\n",
      "/sites/BIHub/Shared Documents/Advisory Data/Main sector/Update/Fact/Ho Chi Minh City/2023/Q2\n",
      "Folder name: \n",
      "Files name: /sites/BIHub/Shared Documents/Advisory Data/Main sector/Update/Fact/Ho Chi Minh City/2023/Q2/Update_VLTH_HCMC_20230630.xlsx\n",
      "Files name: /sites/BIHub/Shared Documents/Advisory Data/Main sector/Update/Fact/Ho Chi Minh City/2023/Q2/UPDATE_APT_HCMC_20230630.xlsx\n"
     ]
    }
   ],
   "source": [
    "#Provide information\n",
    "Province_name=['Ho Chi Minh City']#Chọn tỉnh cần import-- là tên folder \n",
    "Year=['2023']#Chọn năm cần import\n",
    "Quarter=['Q2']#Chọn quý cần import\n",
    "#Có thể chọn nhiều tỉnh, tên tỉnh để trong dấu nháy đơn và cách nhau bởi dấy phẩy. Áp dụng tương tự cho năm, quý\n",
    "#-------------------------------------------------------\n",
    "df_summ_file = pd.DataFrame({'Name':[],'ServerRelativeUrl':[], 'TimeLastModified':[], 'ModTime':[], 'Modified_by_ID':[]})\n",
    "for i in list_folder_sub2:\n",
    "    print(i)\n",
    "    if i.split('/')[-3] in Province_name and i.split('/')[-2] in Year and i.split('/')[-1] in Quarter:\n",
    "        df_summ_file = pd.concat([df_summ_file, eval(sp_object).get_content_url(i)])\n",
    "\n",
    "list_url = df_summ_file['ServerRelativeUrl'].to_list()\n",
    "#History file\n",
    "df_query=pd.DataFrame(df_summ_file).reset_index(drop=True)\n",
    "df_summ_file = df_summ_file.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbe169c",
   "metadata": {},
   "source": [
    "### GET IMPORT FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51e0061a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/sites/BIHub/Shared Documents/Advisory Data/Main sector/Update/Fact/Ho Chi Minh City/2023/Q2/Update_VLTH_HCMC_20230630.xlsx']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = []\n",
    "for i in list_url:\n",
    "    sector = i.split('/')[-1].split('_')[1].upper()\n",
    "    if sector in ('VLTH'): #Chọn sector cần import: RETAIL, OFFICE, SA, HOTEL, APT, VLTH\n",
    "        url.append(i)\n",
    "    else:\n",
    "        pass\n",
    "url"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df571cf7",
   "metadata": {},
   "source": [
    "### IMPORT DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5fa7bc94",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [File_Name, Missing_Values, Flag]\n",
      "Index: []\n",
      "\u001b[32mValidate succesfully\u001b[0m\n",
      "CONNECTION SUCESSFUL IN INSERT TO FRESH FUNCTION!\n",
      "Insert Update_VLTH_HCMC_20230630 to Fresh\n",
      "Insert Update_VLTH_HCMC_20230630 to Fresh\n",
      "Insert Update_VLTH_HCMC_20230630 to Fresh\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:50<00:00, 50.35s/it]\n"
     ]
    }
   ],
   "source": [
    "'''Prepare ingredients''' \n",
    "columns_that_need_unidecode = ['Sub_Project_Name', 'Project_City_Name', 'Project_District_Name']\n",
    "#Create empty df for checking dictionary\n",
    "df_dict = pd.DataFrame(columns=['File_Name', 'Missing_Values', 'Flag'])\n",
    "name_sector = ['RETAIL', 'SA', 'APT', 'VLTH', 'OFFICE', 'HOTEL']\n",
    "engine = create_engine(cnt_str)\n",
    "for i in name_sector:\n",
    "    globals()[f'df_update_{i.lower()}'] = pd.DataFrame([])\n",
    "    globals()[f'df_flat__{i.lower()}'] = pd.DataFrame([])\n",
    "#-------------------------------------------------------\n",
    "'''Get data''' \n",
    "for file_url in tqdm(url):\n",
    "    data, file_name, sector = get_data(relative_url, file_url)\n",
    "    # #-------------------------------------------------------\n",
    "\n",
    "    '''Validation step'''\n",
    "    #Remove unfortmated values\n",
    "    data = remove_unformated_character(data)\n",
    "\n",
    "    #Remove unicode characters\n",
    "    for i in columns_that_need_unidecode:\n",
    "        data[i] = remove_unicode(data[i])\n",
    "    #Check dictionary\n",
    "    # lst_dict = ['City', 'District', 'Type', 'Grade']\n",
    "    # lst_cls = ['Project_City_Name', 'Project_District_Name', 'Sub_Project_Type', 'Grade']\n",
    "    lst_dict = ['City', 'District', 'Grade']\n",
    "    lst_cls = ['Project_City_Name', 'Project_District_Name', 'Grade']\n",
    "    for i, j in zip(lst_cls, lst_dict):\n",
    "        data, df_dict = check_dictionary(df_dict, file_name, data, i, j, sector, engine, sp_object)\n",
    "    print(df_dict)\n",
    "    if len(df_dict) == 0:\n",
    "        print(colored('Validate succesfully','green'))\n",
    "        #-------------------------------------------------------\n",
    "        '''Import data process'''\n",
    "        #Check project key\n",
    "        processed_data, flag_key = check_project_key(file_url, data, sector, engine)\n",
    "        if flag_key == 0:\n",
    "            data = get_project_key(flag_key, processed_data, data, sector, engine)\n",
    "            if sector == 'RETAIL':\n",
    "                df_update_retail = pd.concat([df_update_retail, data], axis=0)\n",
    "                df_flat_retail = get_flat_file(df_update_retail, sector, engine)\n",
    "                flag_update, data = update_flat_file(sector, df_flat_retail, df_update_retail)\n",
    "            elif sector == 'OFFICE':\n",
    "                df_update_office = pd.concat([df_update_office, data], axis=0)\n",
    "                df_flat_office = get_flat_file(df_update_office, sector, engine)\n",
    "                flag_update, data = update_flat_file(sector, df_flat_office, df_update_office)\n",
    "            elif sector == 'HOTEL':\n",
    "                df_update_hotel = pd.concat([df_update_hotel, data], axis=0)\n",
    "                df_flat_hotel = get_flat_file(df_update_hotel, sector, engine)\n",
    "                flag_update, data = update_flat_file(sector, df_flat_hotel, df_update_hotel)\n",
    "            elif sector == 'SA' or sector=='SERVICED_APARTMENT':\n",
    "                df_update_sa = pd.concat([df_update_sa, data], axis=0)\n",
    "                df_flat_sa = get_flat_file(df_update_sa, sector, engine)\n",
    "                flag_update, data = update_flat_file(sector, df_flat_sa, df_update_sa)\n",
    "            elif sector == 'APT' or sector=='APARTMENT':\n",
    "                df_update_apt = pd.concat([df_update_apt, data], axis=0)\n",
    "                df_flat_apt = get_flat_file(df_update_apt, sector, engine)\n",
    "                flag_update, data = update_flat_file(sector, df_flat_apt, df_update_apt)\n",
    "            elif sector == 'VLTH':\n",
    "                df_update_vlth = pd.concat([df_update_vlth, data], axis=0)\n",
    "                df_flat_vlth = get_flat_file(df_update_vlth, sector, engine)\n",
    "                flag_update, data = update_flat_file(sector, df_flat_vlth, df_update_vlth)\n",
    "            #-------------------------------------------------------    \n",
    "            if flag_update == 0:\n",
    "                insert_to_fresh(file_url, data, cnt_str)\n",
    "                list_df_update = [df_update_retail, df_update_office, df_update_hotel, df_update_sa, df_update_apt, df_update_vlth]\n",
    "                for df_update in list_df_update:\n",
    "                    if len(df_update) != 0:\n",
    "                        df_update = Generate_Additional_Columns(df_update,url,df_summ_file,BIHub,engine,file_url)\n",
    "                        insert_to_tracking(df_update, sector, engine)\n",
    "            else:\n",
    "                print(colored(f'Some keys wrong in {file_name}', 'yellow'))\n",
    "                print(data)\n",
    "        else:\n",
    "            print(colored(f'Cant get key in {file_name}', 'yellow'))\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4174a392",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
