{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12012f35",
   "metadata": {},
   "source": [
    "### IMPORT LIBRARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "378258c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from office365.runtime.auth.authentication_context import AuthenticationContext\n",
    "from office365.sharepoint.client_context import ClientContext\n",
    "from office365.sharepoint.files.file import File\n",
    "from office365.runtime.auth.client_credential import ClientCredential\n",
    "from office365.runtime.client_request_exception import ClientRequestException\n",
    "import datetime\n",
    "import pytz\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import glob\n",
    "import pyodbc\n",
    "import os \n",
    "import json\n",
    "from io import BytesIO\n",
    "import io\n",
    "import platform\n",
    "from function.PyToSp import *\n",
    "from tqdm import tqdm\n",
    "from urllib.parse import quote_plus\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, event\n",
    "import pyodbc\n",
    "import requests\n",
    "import inspect\n",
    "from validate import *\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "from urllib.parse import quote_plus\n",
    "import msal\n",
    "from itertools import chain\n",
    "from termcolor import colored\n",
    "from send_email import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8bee114",
   "metadata": {},
   "source": [
    "### CONNECT TO AZURE SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a39960d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "f = open ('database_information.json', \"r\")\n",
    "qq = json.loads(f.read())\n",
    "f.close()\n",
    "ini_cnt_str ='Driver={driver_str};Server=tcp:hkazdevsqld3vnreserch.database.windows.net,1433;database={database};Uid={username};Pwd={password};Encrypt=yes;Authentication=ActiveDirectoryPassword;Connection Timeout=30;'.format(**qq)\n",
    "quoted = quote_plus(ini_cnt_str)\n",
    "cnt_str = 'mssql+pyodbc:///?odbc_connect={}'.format(quoted)\n",
    "engine = create_engine(cnt_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81420039",
   "metadata": {},
   "source": [
    "### CONNECT TO SHAREPOINT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b0587ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Web site title: S22M Internal Hub _ Successful Connection!\n"
     ]
    }
   ],
   "source": [
    "header_BIHub = 'share_point_BIHub'\n",
    "config_BIHub = read_config_json(config_path, header_BIHub)\n",
    "BIHub = SharePoint(config_BIHub)\n",
    "BIHub.check_connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e642c12",
   "metadata": {},
   "source": [
    "### READ AND LIST FOLDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d951e70e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder name: /sites/BIHub/Shared Documents/Advisory Data/Product mix/Flat file/Dong Nai Province\n",
      "/sites/BIHub/Shared Documents/Advisory Data/Product mix/Flat file/Ho Chi Minh City\n",
      "/sites/BIHub/Shared Documents/Advisory Data/Product mix/Flat file/Long An Province\n",
      "/sites/BIHub/Shared Documents/Advisory Data/Product mix/Flat file/Binh Duong Province\n",
      "/sites/BIHub/Shared Documents/Advisory Data/Product mix/Flat file/Ha Noi City\n"
     ]
    }
   ],
   "source": [
    "#Tất cả các tỉnh\n",
    "relative_url = \"/sites/BIHub/Shared Documents/Advisory Data/Product mix/Flat file\"\n",
    "sp_object = relative_url.split('/')[2].replace('-','')\n",
    "list_folder = eval(sp_object).get_content_url(relative_url,return_list_folder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "162f57a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder name: /sites/BIHub/Shared Documents/Advisory Data/Product mix/Flat file/Dong Nai Province/2022\n",
      "Folder name: /sites/BIHub/Shared Documents/Advisory Data/Product mix/Flat file/Ho Chi Minh City/2022\n",
      "Folder name: /sites/BIHub/Shared Documents/Advisory Data/Product mix/Flat file/Long An Province/2022\n",
      "Folder name: /sites/BIHub/Shared Documents/Advisory Data/Product mix/Flat file/Binh Duong Province/2022\n",
      "Folder name: /sites/BIHub/Shared Documents/Advisory Data/Product mix/Flat file/Ha Noi City/2022\n"
     ]
    }
   ],
   "source": [
    "#lấy năm\n",
    "list_folder_sub1=[]\n",
    "for i in list_folder:\n",
    "    ls=eval(sp_object).get_content_url(i,return_list_folder=True)\n",
    "    list_folder_sub1=list_folder_sub1+ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "338da9f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder name: /sites/BIHub/Shared Documents/Advisory Data/Product mix/Flat file/Dong Nai Province/2022/Q2\n",
      "/sites/BIHub/Shared Documents/Advisory Data/Product mix/Flat file/Dong Nai Province/2022/Q3\n",
      "Folder name: /sites/BIHub/Shared Documents/Advisory Data/Product mix/Flat file/Ho Chi Minh City/2022/Q3\n",
      "Folder name: /sites/BIHub/Shared Documents/Advisory Data/Product mix/Flat file/Long An Province/2022/Q2\n",
      "/sites/BIHub/Shared Documents/Advisory Data/Product mix/Flat file/Long An Province/2022/Q3\n",
      "Folder name: /sites/BIHub/Shared Documents/Advisory Data/Product mix/Flat file/Binh Duong Province/2022/Q2\n",
      "/sites/BIHub/Shared Documents/Advisory Data/Product mix/Flat file/Binh Duong Province/2022/Q3\n",
      "Folder name: /sites/BIHub/Shared Documents/Advisory Data/Product mix/Flat file/Ha Noi City/2022/Q3\n"
     ]
    }
   ],
   "source": [
    "#lấy quý\n",
    "list_folder_sub2=[]\n",
    "for i in list_folder_sub1:\n",
    "    ls=eval(sp_object).get_content_url(i,return_list_folder=True)\n",
    "    list_folder_sub2=list_folder_sub2+ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa46fe3c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder name: \n",
      "Files name: /sites/BIHub/Shared Documents/Advisory Data/Product mix/Flat file/Ha Noi City/2022/Q3/PM_Apt_HN_20220930.xlsx\n"
     ]
    }
   ],
   "source": [
    "#Provide information\n",
    "Province_name=['Ha Noi City']#Chọn tỉnh cần import-- là tên folder \n",
    "Year=['2022']#Chọn năm cần import\n",
    "Quarter=['Q3']#Chọn quý cần import\n",
    "#Có thể chọn nhiều tỉnh, tên tỉnh để trong dấu nháy đơn và cách nhau bởi dấy phẩy. Áp dụng tương tự cho năm, quý\n",
    "#-------------------------------------------------------\n",
    "df_summ_file = pd.DataFrame({'Name':[],'ServerRelativeUrl':[], 'TimeLastModified':[], 'ModTime':[], 'Modified_by_ID':[]})\n",
    "for i in list_folder_sub2:\n",
    "    if i.split('/')[7] in Province_name and i.split('/')[8] in Year and i.split('/')[9] in Quarter:\n",
    "        df_summ_file = pd.concat([df_summ_file, eval(sp_object).get_content_url(i)])\n",
    "list_url = df_summ_file['ServerRelativeUrl'].to_list()\n",
    "#History file\n",
    "df_query=pd.DataFrame(df_summ_file).reset_index(drop=True)\n",
    "df_summ_file = df_summ_file.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbe169c",
   "metadata": {},
   "source": [
    "### GET IMPORT FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "51e0061a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/sites/BIHub/Shared Documents/Advisory Data/Product mix/Flat file/Ha Noi City/2022/Q3/PM_Apt_HN_20220930.xlsx']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = []\n",
    "for i in list_url:\n",
    "    sector = i.split('/')[-1].split('_')[1].upper()\n",
    "    if sector in ('APT'):#Chọn sector cần import: RETAIL, OFFICE, SA, HOTEL, APT, VLTH\n",
    "        url.append(i)\n",
    "    else:\n",
    "        pass\n",
    "url"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df571cf7",
   "metadata": {},
   "source": [
    "### IMPORT DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5fa7bc94",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mValidate succesfully\u001b[0m\n",
      "Insert PM_VLTH_Dong Nai_20220930 to Fresh\n",
      "Insert PM_VLTH_Dong Nai_20220930 to Fresh\n",
      "Insert PM_VLTH_Dong Nai_20220930 to Fresh\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|█████████████████████                                                               | 1/4 [00:09<00:27,  9.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mValidate succesfully\u001b[0m\n",
      "Insert PM_VLTH_HCM_20220930 to Fresh\n",
      "Insert PM_VLTH_HCM_20220930 to Fresh\n",
      "Insert PM_VLTH_HCM_20220930 to Fresh\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|██████████████████████████████████████████                                          | 2/4 [00:16<00:16,  8.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mValidate succesfully\u001b[0m\n",
      "Insert PM_VLTH_Long An_20220930 to Fresh\n",
      "Insert PM_VLTH_Long An_20220930 to Fresh\n",
      "Insert PM_VLTH_Long An_20220930 to Fresh\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████████████████████████████████████████████████████████████                     | 3/4 [00:24<00:07,  7.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mValidate succesfully\u001b[0m\n",
      "Insert PM_VLTH_Binh Duong_20220930 to Fresh\n",
      "Insert PM_VLTH_Binh Duong_20220930 to Fresh\n",
      "Insert PM_VLTH_Binh Duong_20220930 to Fresh\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:30<00:00,  7.65s/it]\n"
     ]
    }
   ],
   "source": [
    "'''Prepare ingredients''' \n",
    "columns_that_need_unidecode=['Project_Name','Sub_Project_Name', 'Mix_Name'\n",
    "                            ,'Sub_Project_Type', 'Project_City_Name', 'Project_District_Name']\n",
    "#Create empty df for checking dictionary\n",
    "df_dict = pd.DataFrame(columns=['File_Name', 'Missing_Values', 'Flag'])\n",
    "#Create multi empty df for tracking autdit step\n",
    "name_sector = ['APT', 'VLTH']\n",
    "name_sector = [x.lower() for x in name_sector]\n",
    "for i in name_sector:\n",
    "    globals()['df_temp_flat_{}'.format(i)] = pd.DataFrame([])\n",
    "    globals()['df_flat_{}'.format(i)] = pd.DataFrame([])\n",
    "#-------------------------------------------------------\n",
    "'''Get data''' \n",
    "for file_url in tqdm(url):  \n",
    "    data, file_name, sector = get_data(relative_url, file_url)\n",
    "    #-------------------------------------------------------\n",
    "    data = check_date_key(file_url, data)#Check format date_key in flat file   \n",
    "    '''Check duplicate mix_name'''\n",
    "    #data, df_dup = check_duplicate(data, 'Mix_Name')   \n",
    "    #-------------------------------------------------------\n",
    "    '''Validation step'''\n",
    "    #Remove unfortmated values\n",
    "    data = remove_unformated_character(data)\n",
    "    #Remove unicode characters\n",
    "    for i in columns_that_need_unidecode:\n",
    "        data[i] = remove_unicode(data[i])\n",
    "    #Check dictionary\n",
    "    lst_dict = ['City', 'District', 'Type', 'Grade']\n",
    "    lst_cls = ['Project_City_Name', 'Project_District_Name', 'Sub_Project_Type', 'Grade']\n",
    "    for i, j in zip(lst_cls, lst_dict):\n",
    "        data, df_dict = check_dictionary(df_dict, file_name, data, i, j, sector, engine, sp_object)\n",
    "    if len(df_dict) == 0:\n",
    "        print(colored('Validate succesfully','green'))\n",
    "        #-------------------------------------------------------\n",
    "        '''Import data process'''\n",
    "        #Check project key\n",
    "        data = Generate_Additional_Columns(data,url,df_summ_file,BIHub,engine,file_url)\n",
    "        processed_data, flag_key = check_project_key(file_url, data, sector, engine)\n",
    "        if flag_key == 0:\n",
    "            #Create tracking audit\n",
    "            if sector == 'APT' or sector=='APARTMENT':\n",
    "                df_temp_flat_apt = pd.concat([df_temp_flat_apt, data], axis=0)\n",
    "                df_flat_apt = tracking_flat_file(df_temp_flat_apt, file_url)\n",
    "            elif sector == 'VLTH':\n",
    "                df_temp_flat_vlth = pd.concat([df_temp_flat_vlth, data], axis=0)\n",
    "                df_flat_vlth = tracking_flat_file(df_temp_flat_vlth, file_url)\n",
    "            else:\n",
    "                pass\n",
    "            #Get key \n",
    "            #data = get_project_key(flag_key, processed_data, data, sector, engine)\n",
    "            #insert_to_fresh(file_url, data, engine)\n",
    "        else:\n",
    "            print(colored(f'Cant get key in {file_name}', 'yellow'))\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a40cca",
   "metadata": {},
   "source": [
    "Đang vướng khúc hàm tracking_db, chỗ lấy sector có vấn đề"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7a5663",
   "metadata": {},
   "source": [
    "### SEND EMAIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8aabccc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Sector'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\.conda\\envs\\test4\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3620\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\.conda\\envs\\test4\\lib\\site-packages\\pandas\\_libs\\index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\.conda\\envs\\test4\\lib\\site-packages\\pandas\\_libs\\index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Sector'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 11>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m#Email notify imported data\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m df_flat_html, df_query_html \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_df_to_html\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtype_html\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlist_df\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlist_df_flat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtype_sector\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcnxn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m to_email \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnngocphuonguyen@savills.com.vn\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     13\u001b[0m run_email(type_sector \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPRODUCT MIX\u001b[39m\u001b[38;5;124m'\u001b[39m, email_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m, user_email \u001b[38;5;241m=\u001b[39m to_email, df_flat_html \u001b[38;5;241m=\u001b[39m df_flat_html, df_query_html \u001b[38;5;241m=\u001b[39m df_query_html)\n",
      "File \u001b[1;32m~\\Downloads\\Scripts_Import\\Research\\validate.py:1662\u001b[0m, in \u001b[0;36mconvert_df_to_html\u001b[1;34m(type_html, df, list_df, type_sector, cnxn)\u001b[0m\n\u001b[0;32m   1660\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m type_sector \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m   1661\u001b[0m         df_flat_html \u001b[38;5;241m=\u001b[39m create_content(type_content \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m, type_sector \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m, list_df \u001b[38;5;241m=\u001b[39m list_df, engine \u001b[38;5;241m=\u001b[39m cnxn)\n\u001b[1;32m-> 1662\u001b[0m         df_query_html \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtype_content\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtype_sector\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlist_df\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlist_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcnxn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1663\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m df_flat_html, df_query_html    \n\u001b[0;32m   1665\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m type_html \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m4\u001b[39m: \u001b[38;5;66;03m#check new key\u001b[39;00m\n",
      "File \u001b[1;32m~\\Downloads\\Scripts_Import\\Research\\validate.py:1604\u001b[0m, in \u001b[0;36mcreate_content\u001b[1;34m(type_content, type_sector, list_df, df_noti, engine)\u001b[0m\n\u001b[0;32m   1602\u001b[0m list_df_query \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m   1603\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m df_flat \u001b[38;5;129;01min\u001b[39;00m list_df:\n\u001b[1;32m-> 1604\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mtracking_db\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_flat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1605\u001b[0m     df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mstyle\u001b[38;5;241m.\u001b[39mapply(highlight_diff, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, other\u001b[38;5;241m=\u001b[39mdf_flat) \n\u001b[0;32m   1606\u001b[0m     list_df_query\u001b[38;5;241m.\u001b[39mappend(df)\n",
      "File \u001b[1;32m~\\Downloads\\Scripts_Import\\Research\\validate.py:1353\u001b[0m, in \u001b[0;36mtracking_db\u001b[1;34m(df_flat, engine)\u001b[0m\n\u001b[0;32m   1352\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtracking_db\u001b[39m(df_flat, engine):\n\u001b[1;32m-> 1353\u001b[0m     sector\u001b[38;5;241m=\u001b[39m\u001b[43mdf_flat\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSector\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mupper()\n\u001b[0;32m   1354\u001b[0m     file_name\u001b[38;5;241m=\u001b[39mdf_flat[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFile_Name\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m   1355\u001b[0m     file_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(file_name)[\u001b[38;5;241m1\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32m~\\.conda\\envs\\test4\\lib\\site-packages\\pandas\\core\\frame.py:3505\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3504\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3505\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3507\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\.conda\\envs\\test4\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3623\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3624\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3625\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3626\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3627\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3628\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Sector'"
     ]
    }
   ],
   "source": [
    "list_df_flat = [df_flat_apt, df_flat_vlth]\n",
    "#Email notify missing in dictionary\n",
    "if len(df_dict) != 0:\n",
    "    print(colored('Missing values in dictionary','yellow'))\n",
    "    df_noti_html = convert_df_to_html(type_html = 2, df = df_dict, cnxn = engine)\n",
    "    to_email = ['nngocphuonguyen@savills.com.vn']\n",
    "    run_email(email_type = 2, user_email = to_email, df_noti_html = df_noti_html)\n",
    "else:\n",
    "    pass\n",
    "#Email notify imported data\n",
    "df_flat_html, df_query_html = convert_df_to_html(type_html = 3, list_df = list_df_flat, type_sector = 2, cnxn = engine)\n",
    "to_email = ['nngocphuonguyen@savills.com.vn']\n",
    "run_email(type_sector = 'PRODUCT MIX', email_type = 3, user_email = to_email, df_flat_html = df_flat_html, df_query_html = df_query_html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e64df76",
   "metadata": {},
   "source": [
    "### TRACKING AUDIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ac35b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#insert_to_tracking(list_df_flat, 'Tracking_Product_Mix', engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b169614",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test4",
   "language": "python",
   "name": "test4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
